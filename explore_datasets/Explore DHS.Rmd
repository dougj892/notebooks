---
title: "Explore DHS"
output: html_notebook
---

This notebook performs basic analysis of the India 2015-2016 NFHS (DHS) dataset.

## Datasets
There are several datasets for each DHS survey.  See [here](https://www.dhsprogram.com/data/File-Types-and-Names.cfm) for an explanation of the naming convention. The datasets that I use most often are the households, women, and members dataset. The files for these datasets are named "CCHR...", "CCIR...", and "CCPR..." where CC is the country code. 

## Exploring content

1. Search for the term in the questionnaire




```{r, message=FALSE, include = FALSE}
library(tidyverse)
library(haven)
library(purr)
path <-  "C:/Users/dougj/Documents/Data/DHS/India 2015-16/IAHR74DT"
```

## Importing data
The datasets are massive, so it is often useful to read in a few lines (using the nmax option of read_dta), figure out what variables you need and then read in all observations for just those variables

```{r}
# ID vars -- these variables are necessary for id and weighting.
#  WARNING: DROP THE LEADING "h" IF WORKING WITH WOMEN'S FILE
id_vars <- c("hv005", "hv021", "hv023", "hv024", "hv025")

partial <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 10)

# Create a new dataframe of variable names and labels
getLabels <- function(df) {
  var_names <- colnames(df)
  var_labels <- lapply(df, function(x) attributes(x)$label)
  df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(partial)

# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "internet")) 

# Generate list of variables to analyze using the output from the statement above
# In this case, hv243a is mobile phone ownership and hv208 is TV ownership
# hv270 is wealth quintile, hv207 is ownership of TV
an_vars <- c("hv243a", "hv207", "hv208", "hv270")

# Generate list of all variables to import
all_vars <- c(an_vars, id_vars)

# Import the full dataset just for those variables
# WARNING: THIS TAKES A LONG TIME, SO TRY TO MAKE SURE YOU HAVE ALL THE VARS YOU NEED
# SO YOU ONLY DO IT ONCE
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)

# Set the weight variable
hr$wt <- hr$hv005/1000000

# Generate a sample of the dataset.  For country-wide estimates, it is much faster to 
# use a thin sample of the data and results are still sufficiently precise
hr_sample <-  sample_n(hr, 1000)

```

## Analyzing data
For point estimates, it is Ok to just use weighted means. If you want to generate accurate confidence intervals, you need to take into account the sampling strategy. The code below does that. Guidance on how to analyze data taking into account the sampling strategy can be found [here](https://dhsprogram.com/data/Guide-to-DHS-Statistics/Analyzing_DHS_Data.htm).


```{r}

hr_sample %>% 
  group_by(hv270) %>% 
  summarise_at(c("hv243a", "hv207", "hv208"), funs(weighted.mean(., w=wt)))

hr_sample %>% 
  summarise_at(c("hv243a", "hv207", "hv208"), funs(weighted.mean(., w=wt)))

# DHSdesign<-svydesign(id=dta$v021, strata=dta$v023, weights=dta$wt, data=hr)
```


