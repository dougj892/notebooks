summarise(y_mean = mean(cat_pref),
y_sd = sqrt(mean(cat_pref) * (1 - mean(cat_pref)) / n())) %>%
ungroup()
save(preference_by_state, file = "mrp-files/preference_by_state.rda", version = 2)
load("mrp-files/preference_by_state.rda")
compare <- ggplot(data=preference_by_state, aes(x=state, y=y_mean,group=1)) +
geom_ribbon(aes(ymin=y_mean-y_sd,ymax=y_mean+y_sd,x=state),fill='lightgrey',alpha=.7)+
geom_line(aes(x=state, y=y_mean))+
geom_point()+
scale_y_continuous(breaks=c(0,.25,.5,.75,1),
labels=c("0%","25%","50%","75%","100%"),
limits=c(0,1), expand=c(0,0))+
scale_x_discrete(drop=FALSE)+
scale_colour_manual(values=c('#1f78b4','#33a02c','#e31a1c','#ff7f00',
'#8856a7'))+
theme_bw()+
labs(x="States",y="Cat preference")+
theme(legend.position="none",
axis.title=element_text(size=10),
axis.text.y=element_text(size=10),
axis.text.x=element_text(angle=90,size=8),
legend.title=element_text(size=10),
legend.text=element_text(size=10))
compare2 <- ggplot()+
geom_hline(yintercept = mean(sample$cat_pref),size=.8)+
geom_text(aes(x = 5.2, y = mean(sample$cat_pref)+.025, label = "Sample"))+
scale_y_continuous(breaks=c(0,.25,.5,.75,1),
labels=c("0%","25%","50%","75%","100%"),
limits=c(-0.25,1.25),expand=c(0,0))+
theme_bw()+
labs(x="Popn",y="")+
theme(legend.position="none",
axis.title.y=element_blank(),
axis.title.x=element_text(size=10),
axis.text=element_blank(),
axis.ticks=element_blank(),
legend.title=element_text(size=10),
legend.text=element_text(size=10))
bayesplot_grid(compare,compare2,
grid_args = list(nrow=1, widths = c(8,1)))
fit <- stan_glmer(
cat_pref ~ factor(male) + factor(male) * factor(age) +
(1 | state) + (1 | age) + (1 | eth) + (1 | income),
family = binomial(link = "logit"),
data = sample
)
print(fit)
posterior_prob <- posterior_linpred(fit, transform = TRUE, newdata = poststrat)
poststrat_prob <- posterior_prob %*% poststrat$N / sum(poststrat$N)
model_popn_pref <- c(mean = mean(poststrat_prob), sd = sd(poststrat_prob))
round(model_popn_pref, 3)
sample_popn_pref <- mean(sample$cat_pref)
round(sample_popn_pref, 3)
compare2 <- compare2 +
geom_hline(yintercept = model_popn_pref[1], colour = '#2ca25f', size = 1) +
geom_text(aes(x = 5.2, y = model_popn_pref[1] + .025), label = "MRP", colour = '#2ca25f')
bayesplot_grid(compare, compare2,
grid_args = list(nrow = 1, widths = c(8, 1)))
true_popn_pref <- sum(true_popn$cat_pref * poststrat$N) / sum(poststrat$N)
round(true_popn_pref, 3)
compare2 <- compare2 +
geom_hline(yintercept = mean(true_popn_pref), linetype = 'dashed', size = .8) +
geom_text(aes(x = 5.2, y = mean(true_popn_pref) - .025), label = "True")
bayesplot_grid(compare, compare2,
grid_args = list(nrow = 1, widths = c(8, 1)))
state_df <- data.frame(
State = 1:50,
model_state_sd = rep(-1, 50),
model_state_pref = rep(-1, 50),
sample_state_pref = rep(-1, 50),
true_state_pref = rep(-1, 50),
N = rep(-1, 50)
)
for(i in 1:length(levels(as.factor(poststrat$state)))) {
poststrat_state <- poststrat[poststrat$state == i, ]
posterior_prob_state <- posterior_linpred(
fit,
transform = TRUE,
draws = 1000,
newdata = as.data.frame(poststrat_state)
)
poststrat_prob_state <- (posterior_prob_state %*% poststrat_state$N) / sum(poststrat_state$N)
#This is the estimate for popn in state:
state_df$model_state_pref[i] <- round(mean(poststrat_prob_state), 4)
state_df$model_state_sd[i] <- round(sd(poststrat_prob_state), 4)
#This is the estimate for sample
state_df$sample_state_pref[i] <- round(mean(sample$cat_pref[sample$state == i]), 4)
#And what is the actual popn?
state_df$true_state_pref[i] <-
round(sum(true_popn$cat_pref[true_popn$state == i] * poststrat_state$N) /
sum(poststrat_state$N), digits = 4)
state_df$N[i] <- length(sample$cat_pref[sample$state == i])
}
state_df[c(1,3:6)]
state_df$State <- factor(state_df$State, levels = levels(sample$state))
round(100 * c(
mean = mean(abs(state_df$sample_state_pref-state_df$true_state_pref), na.rm = TRUE),
max = max(abs(state_df$sample_state_pref-state_df$true_state_pref), na.rm = TRUE)
))
round(100 * c(
mean = mean(abs(state_df$model_state_pref-state_df$true_state_pref)),
max = max(abs(state_df$model_state_pref-state_df$true_state_pref))
))
#Summarise by state
compare <- compare +
geom_point(data=state_df, mapping=aes(x=State, y=model_state_pref),
inherit.aes=TRUE,colour='#238b45')+
geom_line(data=state_df, mapping=aes(x=State, y=model_state_pref,group=1),
inherit.aes=TRUE,colour='#238b45')+
geom_ribbon(data=state_df,mapping=aes(x=State,ymin=model_state_pref-model_state_sd,
ymax=model_state_pref+model_state_sd,group=1),
inherit.aes=FALSE,fill='#2ca25f',alpha=.3)+
geom_point(data=state_df, mapping=aes(x=State, y=true_state_pref),
alpha=.5,inherit.aes=TRUE)+
geom_line(data=state_df, mapping=aes(x=State, y=true_state_pref),
inherit.aes = TRUE,linetype='dashed')
bayesplot_grid(compare, compare2,
grid_args = list(nrow = 1, widths = c(8, 1)))
# not evaluated to avoid dependency on tidyverse
sample_alt <- sample %>%
group_by(male, age, income, state, eth) %>%
summarise(N_cat_pref = sum(cat_pref), N = n()) %>%
ungroup()
load("mrp-files/sample_alt.rda")
library(tidyverse)
knitr::opts_knit$set(root.dir = "C:/Users/dougj/Documents/Data")
library(tidyverse)
knitr::opts_knit$set(root.dir = "C:/Users/dougj/Documents/Data")
library(haven)
hr <- read_dta(file.path("IAHR74FL.dta"))
library(tidyverse)
library(haven)
knitr::opts_knit$set(root.dir = "C:/Users/dougj/Documents/Data/DHS/India 2015-16/IAHR74DT")
hr <- read_dta(file.path("IAHR74FL.dta"))
library(tidyverse)
library(haven)
knitr::opts_knit$set(root.dir = "C:/Users/dougj/Documents/Data/DHS/India 2015-16/IAHR74DT")
getwd()
library(tidyverse)
library(haven)
knitr::opts_knit$set(root.dir = "C:/Users/dougj/Documents/Data/DHS/India 2015-16/IAHR74DT")
getwd()
path <-  "C:/Users/dougj/Documents/Data/DHS/India 2015-16/IAHR74DT"
hr <- read_dta(file.path(path, "IAHR74FL.dta"))
?read_dta
hr <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 100)
View(hr)
View(hr)
hr <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 10)
View(hr)
library(tidyverse)
library(haven)
path <-  "C:/Users/dougj/Documents/Data/DHS/India 2015-16/IAHR74DT"
# ID vars -- these variables are necessary for id and weighting.
#
id_vars <- c("hv005", "v005", "v021", "v023", "v024", "v025", "wt")
hr <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 10)
# Set the weight variable. For households, use hv005. The v005 variable takes into account women's nonresponse.
hr$wt <- hr$v005/1000000
View(hr)
names(hr)
attributes(hr$v005)
attributes(hr$hv005)
attributes(hr$hv005)$label
lapply(hr, function(x) attributes(x)$label)
# ID vars -- these variables are necessary for id and weighting.
#  WARNING: REPLACE hv005 with v005 if analyzing the women's file
id_vars <- c("hv005", "v021", "v023", "v024", "v025", "wt")
hr <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 10)
# Create a new dataset of variable names and labels
getLabels <- function(df) {
var_names <- colnames(df)
var_labels <- lapply(df, function(x) attributes(x)$label)
df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(hr)
View(vars)
# Search the dataframe for questions
vars %>% filter(str_subset(var_labels, "phone"))
# ID vars -- these variables are necessary for id and weighting.
#  WARNING: REPLACE hv005 with v005 if analyzing the women's file
id_vars <- c("hv005", "v021", "v023", "v024", "v025", "wt")
hr <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 10)
# Create a new dataframe of variable names and labels
getLabels <- function(df) {
var_names <- colnames(df)
var_labels <- lapply(df, function(x) attributes(x)$label)
df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(hr)
# Search the dataframe for questions
vars %>% filter(str_detect(var_labels, "phone"))
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "phone"))
matches
View(matches)
# Search the dataframe for questions
vars %>% filter(str_detect(var_labels, "phone")) %>% print(n=10)
# Search the dataframe for questions
vars %>% filter(str_detect(var_labels, "phone")) %>% print()
# Search the dataframe for questions
vars %>% filter(str_detect(var_labels, "phone"))
matches <- vars %>% filter(str_detect(var_labels, "phone"))
matches
View(matches)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "tv"))
View(matches)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "tele"))
View(matches)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "phone"))
View(matches)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "tele"))
View(matches)
View(matches)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "state"))
View(matches)
?read_dta
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
all_vars
an_vars
# Generate list of variables to analyze using
an_vars <- c("hv243a", "hv208")
# Generate list of all variables to import
all_vars <- c(an_vars, id_vars)
all_vars
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
View(vars)
partial <- read_dta(file.path(path, "IAHR74FL.dta"), n_max = 10)
View(partial)
View(vars)
View(vars)
# ID vars -- these variables are necessary for id and weighting.
#  WARNING: DROP THE LEADING "h" IF WORKING WITH WOMEN'S FILE
id_vars <- c("hv005", "hv021", "hv023", "hv024", "hv025")
# Generate list of variables to analyze using
an_vars <- c("hv243a", "hv208")
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
# Generate list of all variables to import
all_vars <- c(an_vars, id_vars)
all_vars
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
?sample
# Generate a sample of the dataset.  For country-wide estimates, it is much faster to
# use a thin sample of the data and results are still sufficiently precise
hr_sample <-  sample_n(hr, 1000)
# Set the weight variable
hr$wt <- hr$v005/1000000
# Set the weight variable
hr$wt <- hr$hv005/1000000
# Generate a sample of the dataset.  For country-wide estimates, it is much faster to
# use a thin sample of the data and results are still sufficiently precise
hr_sample <-  sample_n(hr, 1000)
View(vars)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "quintile"))
View(matches)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "wealth"))
View(matches)
# Generate list of variables to analyze using the output from the statement above
# In this case, hv243a is mobile phone ownership and hv208 is TV ownership
# hv270 is wealth quintile
an_vars <- c("hv243a", "hv208", "hb270")
# Generate list of all variables to import
all_vars <- c(an_vars, id_vars)
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
# Generate list of variables to analyze using the output from the statement above
# In this case, hv243a is mobile phone ownership and hv208 is TV ownership
# hv270 is wealth quintile
an_vars <- c("hv243a", "hv208", "hv270")
# Generate list of all variables to import
all_vars <- c(an_vars, id_vars)
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
# Set the weight variable
hr$wt <- hr$hv005/1000000
# Generate a sample of the dataset.  For country-wide estimates, it is much faster to
# use a thin sample of the data and results are still sufficiently precise
hr_sample <-  sample_n(hr, 1000)
hr_sample %>% summarise_at(c("hv243a", "hv208", "hv270"), funs(weighted.mean(., w=wt)))
hr_sample %>%
group_by(hv270) %>%
summarise_at(c("hv243a", "hv208"), funs(weighted.mean(., w=wt)))
View(vars)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "radio"))
View(matches)
# Generate list of variables to analyze using the output from the statement above
# In this case, hv243a is mobile phone ownership and hv208 is TV ownership
# hv270 is wealth quintile, hv207 is ownership of TV
an_vars <- c("hv243a", "hv207", "hv208", "hv270")
# Generate list of all variables to import
all_vars <- c(an_vars, id_vars)
# Import the full dataset just for those variables
hr <- read_dta(file.path(path, "IAHR74FL.dta"), col_select = all_vars)
# Set the weight variable
hr$wt <- hr$hv005/1000000
# Generate a sample of the dataset.  For country-wide estimates, it is much faster to
# use a thin sample of the data and results are still sufficiently precise
hr_sample <-  sample_n(hr, 1000)
hr_sample %>%
group_by(hv270) %>%
summarise_at(c("hv243a", "hv207", "hv208"), funs(weighted.mean(., w=wt)))
# DHSdesign<-svydesign(id=dta$v021, strata=dta$v023, weights=dta$wt, data=hr)
# Search the dataframe for questions
matches <- vars %>% filter(str_detect(var_labels, "internet"))
View(matches)
hr_sample %>% summarize(tv = weighted.mean(hv208, wt))
hr_sample %>%
group_by(hv270) %>%
summarise_at(c("hv243a", "hv207", "hv208"), funs(weighted.mean(., w=wt)))
hr_sample %>%
summarise_at(c("hv243a", "hv207", "hv208"), funs(weighted.mean(., w=wt)))
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS00012"
ind_file <- file.path(ihds_ind_dir, "36151-0002-Data.dta")
ind_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
df <- read_dta(hh_file, nmax = 10)
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
df <- read_dta(hh_file, n_max = 10)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
df <- read_dta(hh_file, n_max = 10)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
df <- read_dta(hh_file, n_max = 10)
library(tidyverse)
library(haven)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
df <- read_dta(hh_file, n_max = 10)
library(tidyverse)
library(haven)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
df <- read_dta(hh_file, n_max = 10)
View(df)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
# read in just those variables that i need
# this is much faster than reading in everything and then selecting
partial <- read_dta(hh_file, n_max = 10)
getLabels <- function(df) {
var_names <- colnames(df)
var_labels <- lapply(df, function(x) attributes(x)$label)
df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(partial)
View(vars)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
id_vars <- c("WT", "STATEID", "DISTID", "PSUID", "HHID", "HHSPLITID", "IDPSU", "WT")
partial <- read_dta(hh_file, n_max = 10)
getLabels <- function(df) {
var_names <- colnames(df)
var_labels <- lapply(df, function(x) attributes(x)$label)
df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(partial)
# MM4C - # of hours TV children
# MM3C - how often TV children
# CGTV - owns TV
an_vars <- c("MM4C", "MM3C", "CGTV")
use_vars <- c(id_vars, an_vars)
hh <- read_dta(hh_file, col_select = use_vars)
View(hh)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
id_vars <- c("WT", "STATEID", "DISTID", "PSUID", "HHID", "HHSPLITID", "IDPSU", "WT", "COPC")
partial <- read_dta(hh_file, n_max = 10)
getLabels <- function(df) {
var_names <- colnames(df)
var_labels <- lapply(df, function(x) attributes(x)$label)
df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(partial)
# MM4C - # of hours TV children
# MM3C - how often TV children
# CGTV - owns TV
an_vars <- c("MM4C", "MM3C", "CGTV")
use_vars <- c(id_vars, an_vars)
hh <- read_dta(hh_file, col_select = use_vars)
hh <- mutate(quintile = ntile(COPC,5))
hh <- hh %>% mutate(quintile = ntile(COPC,5))
sum(is.na(hh$COPC))
hist(hh$COPC)
hh <- hh %>% mutate(quintile = ntile(COPC,5))
hh %>%
group_by(quintile) %>%
summarise_at(tv_own = weighted.mean(CGTV, WT))
hh %>%
group_by(quintile) %>%
summarise(tv_own = weighted.mean(CGTV, WT))
hh %>%
group_by(quintile) %>%
summarise(tv_own = weighted.mean(CGTV, WT, na.rm = TRUE))
hh %>%
summarise(tv_own = weighted.mean(CGTV, WT, na.rm = TRUE))
hh %>%
group_by(quintile) %>%
summarise(tv_own = weighted.mean(CGTV, WT, na.rm = TRUE))
hh %>%
group_by(quintile) %>%
summarise(tv_own = weighted.mean(CGTV, WT, na.rm = TRUE) , n =n)
hh %>%
group_by(quintile) %>%
summarise(tv_own = weighted.mean(CGTV, WT, na.rm = TRUE) , n =n())
table(hh$MM3C)
hh$child_watch <- hh$MM3C >=2
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=wt, na.rm = TRUE)))
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE), n()))
hh$child_watch <- ifelse(is.na(hh$child_watch), 0, hh$child_watch)
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
# check for instances of child
hh %>% filter((CGTV =1) & (MM3C >=2))
# check for instances of child
hh %>% filter((CGTV ==0) & (MM3C >=2))
attributes(hh$CGTV)
hh <- hh %>% mutate(quintile = ntile(COPC,5))
hh$child_watch <- hh$MM3C >=2
hh$child_watch <- ifelse(is.na(hh$child_watch), 0, hh$child_watch)
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
hh %>%
summarise(tv_own = weighted.mean(CGTV, WT, na.rm = TRUE))
# check for instances of child
hh %>% filter((CGTV ==0) & (MM3C >=2))
hh %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
hh <- hh %>% mutate(quintile = ntile(COPC,5))
hh$child_watch <- hh$MM3C >=2
hh$child_watch <- ifelse(is.na(hh$child_watch), 0, hh$child_watch)
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
hh %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
# check for instances of child
hh %>% filter((CGTV ==0) & (MM3C >=2))
library(tidyverse)
library(haven)
library(tidyverse)
library(haven)
ihds_hh_dir <- "C:/Users/dougj/Documents/Data/IHDS/IHDS 2012/DS0002"
hh_file <- file.path(ihds_hh_dir, "36151-0002-Data.dta")
id_vars <- c("WT", "STATEID", "DISTID", "PSUID", "HHID", "HHSPLITID", "IDPSU", "WT", "COPC")
partial <- read_dta(hh_file, n_max = 10)
getLabels <- function(df) {
var_names <- colnames(df)
var_labels <- lapply(df, function(x) attributes(x)$label)
df_new <- tibble(var_mames = var_names, var_labels=var_labels)
}
vars <- getLabels(partial)
# MM4C - # of hours TV children
# MM3C - how often TV children
# CGTV - owns TV
an_vars <- c("MM4C", "MM3C", "CGTV")
use_vars <- c(id_vars, an_vars)
hh <- read_dta(hh_file, col_select = use_vars)
# what portion of
hh %>% filter((CGTV ==0)  %>% count(MM3c)
hh <- hh %>% mutate(quintile = ntile(COPC,5))
hh <- hh %>% mutate(quintile = ntile(COPC,5))
hh$child_watch <- hh$MM3C >=2
hh$child_watch <- ifelse(is.na(hh$child_watch), 0, hh$child_watch)
hh %>%
group_by(quintile) %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
hh %>%
summarise_at(vars(CGTV, child_watch), funs(weighted.mean(., w=WT, na.rm = TRUE)))
# what portion of
hh %>% filter(CGTV ==0)  %>% count(MM3C)
?count
# what portion of
hh %>% group_by(CGTV) %>% summarize(weighted.mean(MM3C, w=WT, na.rm = TRUE))
# what portion of
hh %>% group_by(CGTV) %>% summarize(weighted.mean(child_watch, w=WT, na.rm = TRUE))
# what portion of
hh %>% group_by(CGTV) %>% summarize(weighted.mean(child_watch, w=WT, na.rm = TRUE), n())
# what portion of
hh %>% group_by(CGTV) %>% summarize(mean_watch =weighted.mean(child_watch, w=WT, na.rm = TRUE), n())
